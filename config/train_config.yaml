# Video-to-Video Diffusion Model Training Configuration

# Model Configuration
model:
  in_channels: 3
  latent_dim: 4

  # VAE settings
  vae_base_channels: 64

  # U-Net settings
  unet_model_channels: 128
  unet_num_res_blocks: 2
  unet_attention_levels: [1, 2]
  unet_channel_mult: [1, 2, 4, 4]
  unet_num_heads: 4
  unet_time_embed_dim: 512

  # Diffusion settings
  noise_schedule: 'cosine'  # 'cosine' or 'linear'
  diffusion_timesteps: 1000
  beta_start: 0.0001
  beta_end: 0.02

# Data Configuration
data:
  # Data source (HuggingFace dataset name or local directory)
  data_source: 't2ance/APE-data'
  source_type: 'huggingface'  # 'huggingface', 'directory', or 'list'

  # Video settings
  num_frames: 16
  resolution: [256, 256]  # [height, width]
  stride: 8  # Frame stride for sampling

  # DataLoader settings
  batch_size: 2
  num_workers: 4

# Training Configuration
training:
  # Optimizer
  learning_rate: 0.0001
  optimizer: 'adam'  # 'adam' or 'adamw'
  weight_decay: 0.0

  # Learning rate scheduler
  scheduler_type: 'cosine'  # 'cosine', 'linear', or 'constant'
  warmup_epochs: 5
  min_lr: 0.000001

  # Training settings
  num_epochs: 100
  gradient_accumulation_steps: 1
  use_amp: true  # Mixed precision training
  max_grad_norm: 1.0  # Gradient clipping

  # Logging
  log_interval: 10  # Log every N steps
  val_interval: 1000  # Validate every N steps
  checkpoint_interval: 5000  # Save checkpoint every N steps

  # Paths
  log_dir: 'logs'
  checkpoint_dir: 'checkpoints'

# Inference Configuration
inference:
  sampler_type: 'ddim'  # 'ddim' or 'ddpm'
  num_inference_steps: 20  # Number of denoising steps
  guidance_scale: 1.0  # For classifier-free guidance (not implemented yet)

# Hardware
device: 'cuda'  # 'cuda' or 'cpu'
seed: 42

# Experiment name
experiment_name: 'video_diffusion_v1'
