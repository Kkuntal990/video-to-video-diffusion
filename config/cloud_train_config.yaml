# Cloud Training Configuration for APE-Data
# This config uses HuggingFace streaming to download the full dataset

# Model Configuration
model:
  in_channels: 3
  latent_dim: 4
  vae_base_channels: 128
  unet_model_channels: 256
  unet_num_res_blocks: 2
  unet_attention_levels: [1, 2, 3]
  unet_channel_mult: [1, 2, 4, 8]
  unet_num_heads: 8
  unet_time_embed_dim: 1024
  noise_schedule: 'cosine'
  diffusion_timesteps: 1000
  beta_start: 0.0001
  beta_end: 0.02

# Pretrained Weights Configuration (RECOMMENDED for 6x speedup!)
pretrained:
  use_pretrained: true  # Set to false to train from scratch

  # VAE pretrained weights
  vae:
    enabled: true
    model_name: 'hpcai-tech/OpenSora-VAE-v1.2'  # Recommended
    # Other options:
    # - 'THUDM/CogVideoX-5b'
    # - 'stabilityai/sd-vae-ft-mse'
    method: 'auto'
    inflate_method: 'central'  # For 2D->3D inflation
    freeze_epochs: 5  # Freeze VAE for first 5 epochs

  # Training strategy
  two_phase_training: true
  phase1_epochs: 10  # Phase 1: Freeze VAE and train U-Net
  # Phase 2: Fine-tune entire model

  # Layer-wise learning rates
  layer_lr_multipliers:
    vae_encoder: 0.1
    vae_decoder: 0.1
    unet: 1.0

# Data Configuration - HuggingFace Streaming
data:
  # Data source: 'huggingface' for cloud training, 'local' for local files
  data_source: 'huggingface'

  # HuggingFace dataset configuration
  dataset_name: 't2ance/APE-data'
  streaming: true  # Stream data without downloading everything
  cache_dir: null  # Use default cache or specify path

  # Categories to include
  categories: ['APE', 'non-APE']  # Use both categories

  # Video settings
  num_frames: 16  # Number of CT slices per sample
  resolution: [256, 256]  # H, W

  # CT windowing (for medical imaging)
  window_center: 40  # HU window center for soft tissue
  window_width: 400  # HU window width

  # DataLoader settings
  batch_size: 4  # Adjust based on GPU memory
  num_workers: 4  # Number of data loading workers
  pin_memory: true
  drop_last: true

# Training Configuration
training:
  num_epochs: 50
  learning_rate: 1e-4
  weight_decay: 0.01

  # Optimization
  optimizer: 'adamw'  # 'adam' or 'adamw'
  gradient_accumulation_steps: 1
  max_grad_norm: 1.0  # Gradient clipping

  # Mixed precision training (highly recommended for speed)
  mixed_precision: true  # Use 'fp16' or 'bf16' on supported hardware
  precision: 'fp16'  # 'fp16' or 'bf16'

  # Learning rate scheduling
  scheduler: 'cosine'  # 'cosine', 'linear', or 'constant'
  warmup_steps: 500

  # Checkpointing
  checkpoint_every: 500  # Save every N steps
  keep_last_n_checkpoints: 5  # Only keep last N checkpoints

  # Validation
  validate_every: 1000
  num_validation_samples: 10

  # Logging
  log_every: 50  # Log every N steps
  output_dir: './outputs'  # Output directory
  experiment_name: 'ape_v2v_diffusion'

  # Weights & Biases (optional)
  use_wandb: false  # Set to true to enable W&B logging
  wandb_project: 'video-diffusion'
  wandb_entity: null  # Your W&B username/team

# Hardware Configuration
hardware:
  device: 'cuda'  # 'cuda' for GPU, 'cpu' for CPU
  num_gpus: 1  # Number of GPUs to use
  distributed: false  # Set to true for multi-GPU training

  # Memory optimization
  gradient_checkpointing: false  # Enable if running out of memory
  cpu_offload: false  # Offload to CPU if needed

# Inference Configuration (for validation)
inference:
  sampler: 'ddim'  # 'ddim' or 'ddpm'
  num_inference_steps: 50  # Number of denoising steps
  guidance_scale: 1.0  # Classifier-free guidance scale
  save_samples: true  # Save generated samples during validation
  samples_per_validation: 5  # Number of samples to generate

# Resume Training
resume:
  checkpoint_path: null  # Path to checkpoint to resume from
  resume_optimizer: true  # Resume optimizer state
  resume_scheduler: true  # Resume scheduler state

# Early Stopping (optional)
early_stopping:
  enabled: false
  patience: 10  # Stop if no improvement for N validations
  metric: 'loss'  # Metric to monitor
  mode: 'min'  # 'min' or 'max'

# Notes:
# 1. Adjust batch_size based on GPU memory:
#    - 24GB GPU (RTX 3090/4090): batch_size 2-4
#    - 40GB GPU (A100): batch_size 4-8
#    - 80GB GPU (A100): batch_size 8-16
#
# 2. With pretrained weights:
#    - Training time: ~1 day on A100
#    - Expected PSNR improvement: +15-20%
#
# 3. Without pretrained weights:
#    - Training time: ~7 days on A100
#    - Slower convergence
#
# 4. For faster iteration during development:
#    - Reduce num_frames to 8
#    - Reduce resolution to [128, 128]
#    - Increase checkpoint_every to save disk space
