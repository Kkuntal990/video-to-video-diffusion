apiVersion: batch/v1
kind: Job
metadata:
  name: ape-dataset-download-job
  labels:
    app: v2v-diffusion
    task: dataset-download
    gpu: none
spec:
  template:
    metadata:
      labels:
        app: v2v-diffusion
        task: dataset-download
    spec:
      containers:
      - name: downloader
        image: ghcr.io/kkuntal990/v2v-diffusion:latest
        imagePullPolicy: Always

        command: ["/bin/bash"]
        args:
          - "-c"
          - |
            echo "Starting APE dataset download..."
            echo "Node: $(hostname)"
            echo ""

            python3 scripts/download_ape_dataset.py \
              --output_dir /workspace/storage_a100/dataset \
              --dataset_name t2ance/APE-data \
              --split train \
              --verbose

            echo ""
            echo "Download completed!"

        # Resource requests
        resources:
          requests:
            memory: "16Gi"
            cpu: "4"
          limits:
            memory: "16Gi"
            cpu: "4"

        # Volume mounts
        volumeMounts:
        - name: storage
          mountPath: /workspace/storage_a100

        # Environment variables
        env:
        - name: PYTHONUNBUFFERED
          value: "1"
        - name: HF_HOME
          value: "/workspace/storage_a100/.cache/huggingface"
        - name: TRANSFORMERS_CACHE
          value: "/workspace/storage_a100/.cache/huggingface"
        - name: HF_DATASETS_CACHE
          value: "/workspace/storage_a100/.cache/huggingface"
        - name: HF_TOKEN
          valueFrom:
            secretKeyRef:
              name: hf-token
              key: HF_TOKEN

      # Volumes
      volumes:
      - name: storage
        persistentVolumeClaim:
          claimName: v2v-diffuser-kuntal-a100

      # Restart policy
      restartPolicy: OnFailure

  # Job completion settings
  backoffLimit: 3  # Retry up to 3 times on failure
  ttlSecondsAfterFinished: 86400  # Keep job for 24 hours after completion

---
# Optional: Create a completion notification ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: dataset-download-info
data:
  instructions: |
    APE Dataset Download Job
    ========================

    This job downloads the APE dataset from HuggingFace to the PVC.

    Monitor progress:
      kubectl logs -f $(kubectl get pods -l job-name=ape-dataset-download-job -o jsonpath='{.items[0].metadata.name}')

    Check job status:
      kubectl get job ape-dataset-download-job

    Verify download after completion:
      kubectl exec copy-pod -- ls -lh /workspace/storage_a100/dataset/APE/ | wc -l
      kubectl exec copy-pod -- ls -lh /workspace/storage_a100/dataset/non-APE/ | wc -l

    Expected results:
      - APE/: ~189 .zip files
      - non-APE/: ~167 .zip files (actually labeled "non APE" with space)
      - Total: ~356 files
      - Size: ~50 GB

    Clean up job after verification:
      kubectl delete job ape-dataset-download-job
