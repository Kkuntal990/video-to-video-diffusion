"""
Test Complete Slice Interpolation Integration

Tests the complete pipeline:
1. Custom MAISI VAE with 100% pretrained weights
2. Slice interpolation with variable depth handling
3. U-Net denoising with proper conditioning
"""

import sys
sys.path.append('.')

import torch
from models.model import VideoToVideoDiffusion

print("="*80)
print("TESTING SLICE INTERPOLATION INTEGRATION")
print("="*80)

# Create config for custom MAISI VAE
config = {
    'in_channels': 1,  # Grayscale CT
    'latent_dim': 4,
    'vae_base_channels': 64,
    'unet_model_channels': 128,
    'unet_num_res_blocks': 2,
    'unet_attention_levels': [1, 2],
    'unet_channel_mult': [1, 2, 4, 4],
    'unet_num_heads': 4,
    'unet_time_embed_dim': 512,
    'noise_schedule': 'cosine',
    'diffusion_timesteps': 1000,
    'pretrained': {
        'use_pretrained': True,
        'vae': {
            'enabled': True,
            'use_custom_maisi': True,
            'checkpoint_path': './pretrained/maisi_vae/models/autoencoder.pt'
        }
    }
}

print("\n" + "="*80)
print("STEP 1: Initialize Model with Custom MAISI VAE")
print("="*80)

try:
    model = VideoToVideoDiffusion(config)
    print("âœ“ Model initialized successfully!")

    # Count parameters
    params = model.count_parameters()
    print(f"\nParameter counts:")
    print(f"  Total: {params['total']:,}")
    print(f"  VAE: {params['vae']:,}")
    print(f"  U-Net: {params['unet']:,}")

except Exception as e:
    print(f"âœ— Failed to initialize model: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

print("\n" + "="*80)
print("STEP 2: Test Encode/Decode with Variable Depth")
print("="*80)

try:
    model.eval()

    # Simulate thick slices: 50 slices @ 5.0mm spacing
    # After patches: 8 slices per patch
    thick = torch.randn(2, 1, 8, 256, 256)  # (B=2, C=1, D=8, H=256, W=256)
    print(f"\nThick slices input: {thick.shape}")

    # Simulate thin slices: 5Ã— interpolation = 40 slices (8â†’40)
    thin = torch.randn(2, 1, 40, 256, 256)  # (B=2, C=1, D=40, H=256, W=256)
    print(f"Thin slices target: {thin.shape}")

    with torch.no_grad():
        # Encode both
        z_thick = model.vae.encode(thick)
        z_thin = model.vae.encode(thin)

        print(f"\nEncoded thick latent: {z_thick.shape}")
        print(f"Encoded thin latent: {z_thin.shape}")

        # Expected: thick (2, 4, 2, 32, 32) - depth compressed 8â†’2 (4Ã—)
        # Expected: thin (2, 4, 10, 32, 32) - depth compressed 40â†’10 (4Ã—)

        # Verify compression ratios
        depth_compression_thick = thick.shape[2] / z_thick.shape[2]
        depth_compression_thin = thin.shape[2] / z_thin.shape[2]
        spatial_compression = thick.shape[3] / z_thick.shape[3]

        print(f"\nCompression ratios:")
        print(f"  Depth: {depth_compression_thick:.1f}Ã— (thick), {depth_compression_thin:.1f}Ã— (thin)")
        print(f"  Spatial: {spatial_compression:.1f}Ã—")

        # Decode
        thick_recon = model.vae.decode(z_thick)
        thin_recon = model.vae.decode(z_thin)

        print(f"\nReconstructed thick: {thick_recon.shape}")
        print(f"Reconstructed thin: {thin_recon.shape}")

        # Compute reconstruction error
        mse_thick = torch.mean((thick - thick_recon) ** 2).item()
        mse_thin = torch.mean((thin - thin_recon) ** 2).item()

        print(f"\nReconstruction MSE:")
        print(f"  Thick: {mse_thick:.6f}")
        print(f"  Thin: {mse_thin:.6f}")

        if mse_thick < 2.0 and mse_thin < 2.0:
            print("âœ“ Encode/decode working correctly!")
        else:
            print("âš  High MSE - expected with random input")

except Exception as e:
    print(f"âœ— Encode/decode failed: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

print("\n" + "="*80)
print("STEP 3: Test Forward Pass (Training)")
print("="*80)

try:
    # Test forward pass with variable depth
    print(f"\nInput shapes:")
    print(f"  Thick (input): {thick.shape}")
    print(f"  Thin (target): {thin.shape}")

    # Forward pass
    loss, metrics = model(thick, thin)

    print(f"\nâœ“ Forward pass successful!")
    print(f"  Loss: {loss.item():.6f}")
    print(f"  Metrics: {metrics}")

except Exception as e:
    print(f"âœ— Forward pass failed: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

print("\n" + "="*80)
print("STEP 4: Test Generate (Inference)")
print("="*80)

try:
    # Test generation with target_depth parameter
    print(f"\nGenerating thin slices from thick slices...")
    print(f"  Input thick: {thick.shape}")
    print(f"  Target depth: {thin.shape[2]} slices")

    with torch.no_grad():
        generated = model.generate(
            thick,
            sampler='ddpm',
            num_inference_steps=10,  # Use fewer steps for testing
            target_depth=thin.shape[2]  # Target 40 slices
        )

    print(f"\nâœ“ Generation successful!")
    print(f"  Generated shape: {generated.shape}")
    print(f"  Expected shape: {thin.shape}")

    if generated.shape == thin.shape:
        print("âœ“ Output shape matches target!")
    else:
        print(f"âš  Shape mismatch: {generated.shape} vs {thin.shape}")

except Exception as e:
    print(f"âœ— Generation failed: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

print("\n" + "="*80)
print("âœ… ALL TESTS PASSED!")
print("="*80)
print("\nIntegration summary:")
print("  âœ“ Custom MAISI VAE loaded with 100% pretrained weights")
print("  âœ“ Variable depth encoding/decoding works")
print("  âœ“ Slice interpolation conditioning works")
print("  âœ“ Forward pass (training) works")
print("  âœ“ Generate (inference) works")
print("\nðŸŽ‰ Complete slice interpolation pipeline is ready!")
print("="*80)
