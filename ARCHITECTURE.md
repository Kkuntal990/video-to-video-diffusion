# Video-to-Video Diffusion Model Architecture

Complete architecture specification with layer dimensions and data flow diagrams.

---

## Table of Contents
1. [Overview](#overview)
2. [Model Architecture](#model-architecture)
3. [VAE Architecture](#vae-architecture)
4. [U-Net Architecture](#unet-architecture)
5. [Diffusion Process](#diffusion-process)
6. [Training Strategy](#training-strategy)
7. [Layer Dimensions](#layer-dimensions)

---

## Overview

**Model Type**: Video-to-Video Diffusion with 3D VAE
**Task**: Medical CT scan reconstruction and enhancement
**Input**: Source CT video (8 slices, 128Ã—128)
**Output**: Enhanced CT video (8 slices, 128Ã—128)

### High-Level Architecture

```
Input Video (BÃ—3Ã—8Ã—128Ã—128)
          â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   VAE       â”‚  Encode to latent space
    â”‚   Encoder   â”‚  (BÃ—4Ã—8Ã—16Ã—16)
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Add       â”‚  Forward diffusion
    â”‚   Noise     â”‚  (training only)
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   U-Net     â”‚  Denoise latent
    â”‚   Denoiser  â”‚  (BÃ—4Ã—8Ã—16Ã—16)
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   VAE       â”‚  Decode to video
    â”‚   Decoder   â”‚  (BÃ—3Ã—8Ã—128Ã—128)
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
Output Video (BÃ—3Ã—8Ã—128Ã—128)
```

### Model Statistics

| Component | Parameters | Input Shape | Output Shape |
|-----------|-----------|-------------|--------------|
| **VAE Encoder** | 86M | (B,3,8,128,128) | (B,4,8,16,16) |
| **VAE Decoder** | 86M | (B,4,8,16,16) | (B,3,8,128,128) |
| **U-Net (4-level)** | 270M | (B,4,8,16,16) | (B,4,8,16,16) |
| **Total** | **441M** | - | - |

**Compression Ratio**: 8Ã— spatial (128â†’16), no temporal compression

---

## Model Architecture

### Complete Forward Pass

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Video-to-Video Diffusion                      â”‚
â”‚                                                                   â”‚
â”‚  Input (v_in)              Target (v_gt)                         â”‚
â”‚  [B,3,8,128,128]          [B,3,8,128,128]                       â”‚
â”‚        â”‚                        â”‚                                â”‚
â”‚        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                â”‚
â”‚        â”‚    VAE Encoding        â”‚                                â”‚
â”‚        â–¼                        â–¼                                â”‚
â”‚   z_in [B,4,8,16,16]      z_gt [B,4,8,16,16]                    â”‚
â”‚        â”‚                        â”‚                                â”‚
â”‚        â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚        â”‚              â”‚  Add Noise (t)    â”‚                      â”‚
â”‚        â”‚              â”‚  Îµ ~ N(0,1)       â”‚                      â”‚
â”‚        â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚        â”‚                        â”‚                                â”‚
â”‚        â”‚                  z_noisy [B,4,8,16,16]                  â”‚
â”‚        â”‚                        â”‚                                â”‚
â”‚        â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º   U-Net Denoiser  â”‚                      â”‚
â”‚         (condition)    â”‚   (predict Îµ)     â”‚                      â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                                  â”‚                                â”‚
â”‚                           Îµ_pred [B,4,8,16,16]                    â”‚
â”‚                                  â”‚                                â”‚
â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚                        â”‚   MSE Loss        â”‚                      â”‚
â”‚                        â”‚   L = ||Îµ - Îµ_pred||Â²                   â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                                                                   â”‚
â”‚  Inference Only:                                                  â”‚
â”‚  z_pred â†’ VAE Decoder â†’ v_out [B,3,8,128,128]                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## VAE Architecture

### VAE Encoder

**Purpose**: Compress video from pixel space to latent space

```
Input: (B, 3, T, H, W) = (B, 3, 8, 128, 128)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     VAE Encoder                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  Conv_in (3â†’128)                                            â”‚
â”‚  [B,3,8,128,128] â”€â”€â†’ [B,128,8,128,128]                     â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚  Down Block 1                         â”‚                  â”‚
â”‚  â”‚  â€¢ ResBlock3D (128â†’128)               â”‚                  â”‚
â”‚  â”‚  â€¢ ResBlock3D (128â†’128)               â”‚                  â”‚
â”‚  â”‚  â€¢ Downsample (128â†’256, /2 spatial)   â”‚                  â”‚
â”‚  â”‚  [B,128,8,128,128] â†’ [B,256,8,64,64] â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚  Down Block 2                         â”‚                  â”‚
â”‚  â”‚  â€¢ ResBlock3D (256â†’256)               â”‚                  â”‚
â”‚  â”‚  â€¢ ResBlock3D (256â†’256)               â”‚                  â”‚
â”‚  â”‚  â€¢ Downsample (256â†’512, /2 spatial)   â”‚                  â”‚
â”‚  â”‚  [B,256,8,64,64] â†’ [B,512,8,32,32]   â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚  Down Block 3                         â”‚                  â”‚
â”‚  â”‚  â€¢ ResBlock3D (512â†’512)               â”‚                  â”‚
â”‚  â”‚  â€¢ ResBlock3D (512â†’512)               â”‚                  â”‚
â”‚  â”‚  â€¢ Downsample (512â†’512, /2 spatial)   â”‚                  â”‚
â”‚  â”‚  [B,512,8,32,32] â†’ [B,512,8,16,16]   â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚  Middle Blocks                        â”‚                  â”‚
â”‚  â”‚  â€¢ ResBlock3D (512â†’512)               â”‚                  â”‚
â”‚  â”‚  â€¢ ResBlock3D (512â†’512)               â”‚                  â”‚
â”‚  â”‚  [B,512,8,16,16] â†’ [B,512,8,16,16]   â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                             â”‚
â”‚  Conv_out (512â†’4, kernel=1)                                 â”‚
â”‚  [B,512,8,16,16] â”€â”€â†’ [B,4,8,16,16]                         â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Output: (B, 4, 8, 16, 16) - Latent representation
```

### VAE Decoder

**Purpose**: Reconstruct video from latent space to pixel space

```
Input: (B, 4, T, h, w) = (B, 4, 8, 16, 16)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     VAE Decoder                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  Conv_in (4â†’512)                                            â”‚
â”‚  [B,4,8,16,16] â”€â”€â†’ [B,512,8,16,16]                         â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚  Middle Blocks                        â”‚                  â”‚
â”‚  â”‚  â€¢ ResBlock3D (512â†’512)               â”‚                  â”‚
â”‚  â”‚  â€¢ ResBlock3D (512â†’512)               â”‚                  â”‚
â”‚  â”‚  [B,512,8,16,16] â†’ [B,512,8,16,16]   â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚  Up Block 1                           â”‚                  â”‚
â”‚  â”‚  â€¢ Upsample (512â†’512, Ã—2 spatial)     â”‚                  â”‚
â”‚  â”‚  â€¢ ResBlock3D (512â†’512)               â”‚                  â”‚
â”‚  â”‚  â€¢ ResBlock3D (512â†’512)               â”‚                  â”‚
â”‚  â”‚  [B,512,8,16,16] â†’ [B,512,8,32,32]   â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚  Up Block 2                           â”‚                  â”‚
â”‚  â”‚  â€¢ Upsample (512â†’256, Ã—2 spatial)     â”‚                  â”‚
â”‚  â”‚  â€¢ ResBlock3D (256â†’256)               â”‚                  â”‚
â”‚  â”‚  â€¢ ResBlock3D (256â†’256)               â”‚                  â”‚
â”‚  â”‚  [B,512,8,32,32] â†’ [B,256,8,64,64]   â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚  Up Block 3                           â”‚                  â”‚
â”‚  â”‚  â€¢ Upsample (256â†’128, Ã—2 spatial)     â”‚                  â”‚
â”‚  â”‚  â€¢ ResBlock3D (128â†’128)               â”‚                  â”‚
â”‚  â”‚  â€¢ ResBlock3D (128â†’128)               â”‚                  â”‚
â”‚  â”‚  [B,256,8,64,64] â†’ [B,128,8,128,128] â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                             â”‚
â”‚  Conv_out (128â†’3, kernel=3)                                 â”‚
â”‚  [B,128,8,128,128] â”€â”€â†’ [B,3,8,128,128]                     â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Output: (B, 3, 8, 128, 128) - Reconstructed video
```

### Building Blocks

#### ResBlock3D
```
Input (C channels)
      â”‚
      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” (skip connection)
      â”‚                â”‚
      â–¼                â”‚
  Conv3D (Câ†’C)         â”‚
  GroupNorm            â”‚
  SiLU                 â”‚
      â”‚                â”‚
      â–¼                â”‚
  Conv3D (Câ†’C)         â”‚
  GroupNorm            â”‚
      â”‚                â”‚
      â–¼                â”‚
    Add â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
    SiLU
      â”‚
   Output
```

#### DownsampleBlock
```
Input (C_in channels, HÃ—W spatial)
      â”‚
      â–¼
  Conv3D (C_in â†’ C_out)
  kernel: (3,4,4)
  stride: (1,2,2)  â† Downsample spatial only
      â”‚
      â–¼
  GroupNorm
      â”‚
      â–¼
    SiLU
      â”‚
   Output (C_out channels, H/2 Ã— W/2 spatial)
```

#### UpsampleBlock
```
Input (C_in channels, HÃ—W spatial)
      â”‚
      â–¼
  ConvTranspose3D (C_in â†’ C_out)
  kernel: (3,4,4)
  stride: (1,2,2)  â† Upsample spatial only
      â”‚
      â–¼
  GroupNorm
      â”‚
      â–¼
    SiLU
      â”‚
   Output (C_out channels, HÃ—2 Ã— WÃ—2 spatial)
```

---

## U-Net Architecture

### 3D U-Net Denoiser

**Purpose**: Denoise latent representations conditioned on input

```
Inputs:
  - Noisy latent: (B, 4, 8, 16, 16)
  - Timestep: (B,)
  - Condition: (B, 4, 8, 16, 16)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      3D U-Net Denoiser                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  Time Embedding (Sinusoidal)                                  â”‚
â”‚  t [B] â”€â”€â†’ t_emb [B,1024]                                    â”‚
â”‚                                                               â”‚
â”‚  Input Processing                                             â”‚
â”‚  z_noisy [B,4,8,16,16] â”€â”€â†’ Conv_in â”€â”€â†’ [B,128,8,16,16]      â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚                 Encoder Path (4 levels)              â”‚     â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”‚
â”‚  â”‚                                                      â”‚     â”‚
â”‚  â”‚  Level 0: [B,128,8,16,16]                           â”‚     â”‚
â”‚  â”‚  â€¢ ResBlock (128, t_emb)                            â”‚ â”€â”€â”€â”€â”¼â”€â”€â”
â”‚  â”‚  â€¢ ResBlock (128, t_emb)                            â”‚     â”‚  â”‚
â”‚  â”‚  â€¢ Downsample â†’ [B,256,8,8,8]                       â”‚     â”‚  â”‚
â”‚  â”‚                                                      â”‚     â”‚  â”‚
â”‚  â”‚  Level 1: [B,256,8,8,8]                             â”‚     â”‚  â”‚
â”‚  â”‚  â€¢ ResBlock (256, t_emb)                            â”‚ â”€â”€â”€â”€â”¼â”€â”€â”¼â”€â”€â”
â”‚  â”‚  â€¢ ResBlock (256, t_emb)                            â”‚     â”‚  â”‚  â”‚
â”‚  â”‚  â€¢ Attention (heads=8)                               â”‚     â”‚  â”‚  â”‚
â”‚  â”‚  â€¢ Downsample â†’ [B,512,8,4,4]                       â”‚     â”‚  â”‚  â”‚
â”‚  â”‚                                                      â”‚     â”‚  â”‚  â”‚
â”‚  â”‚  Level 2: [B,512,8,4,4]                             â”‚     â”‚  â”‚  â”‚
â”‚  â”‚  â€¢ ResBlock (512, t_emb)                            â”‚ â”€â”€â”€â”€â”¼â”€â”€â”¼â”€â”€â”¼â”€â”€â”
â”‚  â”‚  â€¢ ResBlock (512, t_emb)                            â”‚     â”‚  â”‚  â”‚  â”‚
â”‚  â”‚  â€¢ Attention (heads=8)                               â”‚     â”‚  â”‚  â”‚  â”‚
â”‚  â”‚  â€¢ Downsample â†’ [B,512,8,2,2]                       â”‚     â”‚  â”‚  â”‚  â”‚
â”‚  â”‚                                                      â”‚     â”‚  â”‚  â”‚  â”‚
â”‚  â”‚  Level 3 (Bottleneck): [B,512,8,2,2]                â”‚     â”‚  â”‚  â”‚  â”‚
â”‚  â”‚  â€¢ ResBlock (512, t_emb)                            â”‚     â”‚  â”‚  â”‚  â”‚
â”‚  â”‚  â€¢ ResBlock (512, t_emb)                            â”‚     â”‚  â”‚  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â”‚  â”‚  â”‚
â”‚                                                               â”‚  â”‚  â”‚  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚  â”‚  â”‚  â”‚
â”‚  â”‚            Middle Block (at bottleneck)              â”‚     â”‚  â”‚  â”‚  â”‚
â”‚  â”‚  â€¢ ResBlock (512, t_emb)                            â”‚     â”‚  â”‚  â”‚  â”‚
â”‚  â”‚  â€¢ TemporalAttention (heads=8)                       â”‚     â”‚  â”‚  â”‚  â”‚
â”‚  â”‚  â€¢ ResBlock (512, t_emb)                            â”‚     â”‚  â”‚  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â”‚  â”‚  â”‚
â”‚                                                               â”‚  â”‚  â”‚  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚  â”‚  â”‚  â”‚
â”‚  â”‚                 Decoder Path (4 levels)              â”‚     â”‚  â”‚  â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”‚  â”‚  â”‚  â”‚
â”‚  â”‚                                                      â”‚     â”‚  â”‚  â”‚  â”‚
â”‚  â”‚  Level 3 â†’ 2: [B,512,8,2,2]                         â”‚     â”‚  â”‚  â”‚  â”‚
â”‚  â”‚  â€¢ Concat skip â† [B,512,8,2,2] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”¼â”€â”€â”¼â”€â”€â”˜
â”‚  â”‚  â€¢ ResBlock (1024â†’512, t_emb)                       â”‚     â”‚  â”‚  â”‚
â”‚  â”‚  â€¢ ResBlock (512, t_emb)                            â”‚     â”‚  â”‚  â”‚
â”‚  â”‚  â€¢ Upsample â†’ [B,512,8,4,4]                         â”‚     â”‚  â”‚  â”‚
â”‚  â”‚                                                      â”‚     â”‚  â”‚  â”‚
â”‚  â”‚  Level 2 â†’ 1: [B,512,8,4,4]                         â”‚     â”‚  â”‚  â”‚
â”‚  â”‚  â€¢ Concat skip â† [B,512,8,4,4] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”¼â”€â”€â”˜
â”‚  â”‚  â€¢ ResBlock (1024â†’512, t_emb)                       â”‚     â”‚  â”‚
â”‚  â”‚  â€¢ ResBlock (512, t_emb)                            â”‚     â”‚  â”‚
â”‚  â”‚  â€¢ Attention (heads=8)                               â”‚     â”‚  â”‚
â”‚  â”‚  â€¢ Upsample â†’ [B,512,8,8,8]                         â”‚     â”‚  â”‚
â”‚  â”‚                                                      â”‚     â”‚  â”‚
â”‚  â”‚  Level 1 â†’ 0: [B,512,8,8,8]                         â”‚     â”‚  â”‚
â”‚  â”‚  â€¢ Concat skip â† [B,256,8,8,8] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”¼â”€â”€â”˜
â”‚  â”‚  â€¢ ResBlock (768â†’256, t_emb)                        â”‚     â”‚  â”‚
â”‚  â”‚  â€¢ ResBlock (256, t_emb)                            â”‚     â”‚  â”‚
â”‚  â”‚  â€¢ Attention (heads=8)                               â”‚     â”‚  â”‚
â”‚  â”‚  â€¢ Upsample â†’ [B,256,8,16,16]                       â”‚     â”‚  â”‚
â”‚  â”‚                                                      â”‚     â”‚  â”‚
â”‚  â”‚  Level 0 (final): [B,256,8,16,16]                   â”‚     â”‚  â”‚
â”‚  â”‚  â€¢ Concat skip â† [B,128,8,16,16] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”˜
â”‚  â”‚  â€¢ ResBlock (384â†’128, t_emb)                        â”‚     â”‚
â”‚  â”‚  â€¢ ResBlock (128, t_emb)                            â”‚     â”‚
â”‚  â”‚  â€¢ ResBlock (128, t_emb)                            â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                               â”‚
â”‚  Output Projection                                            â”‚
â”‚  [B,128,8,16,16] â”€â”€â†’ Conv_out â”€â”€â†’ [B,4,8,16,16]             â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Output: Îµ_pred [B,4,8,16,16] - Predicted noise
```

### U-Net Building Blocks

#### ResBlockWithTimeEmbed
```
Input: z [B,C,T,H,W], t_emb [B,1024]

      z                  t_emb
      â”‚                    â”‚
      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
      â”‚            â”‚       â–¼
      â–¼            â”‚   Linear (1024â†’C)
  GroupNorm        â”‚       â”‚
      â”‚            â”‚       â–¼
      â–¼            â”‚    SiLU
    SiLU           â”‚       â”‚
      â”‚            â”‚       â””â”€â”€â”€â”€â”€â”€â”
      â–¼            â”‚              â”‚
  Conv3D (Câ†’C)     â”‚              â”‚
      â”‚            â”‚              â”‚
      â–¼            â”‚              â”‚
  GroupNorm        â”‚              â”‚
      â”‚            â”‚              â”‚
   Add â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  (add time emb)
      â”‚            â”‚
      â–¼            â”‚
    SiLU           â”‚
      â”‚            â”‚
      â–¼            â”‚
  Conv3D (Câ†’C)     â”‚
      â”‚            â”‚
      â–¼            â”‚
    Add â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  (skip connection)
      â”‚
   Output
```

#### SpatialTransformer3D (Attention)
```
Input: [B,C,T,H,W]

      â”‚
      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” (skip)
      â”‚           â”‚
      â–¼           â”‚
  Reshape to      â”‚
  [B,TÃ—HÃ—W,C]     â”‚
      â”‚           â”‚
      â–¼           â”‚
  LayerNorm       â”‚
      â”‚           â”‚
      â–¼           â”‚
  Multi-Head      â”‚
  Self-Attention  â”‚
  (heads=8)       â”‚
      â”‚           â”‚
      â–¼           â”‚
  Feed-Forward    â”‚
  Network         â”‚
      â”‚           â”‚
      â–¼           â”‚
  Reshape to      â”‚
  [B,C,T,H,W]     â”‚
      â”‚           â”‚
      â–¼           â”‚
    Add â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
   Output
```

---

## Diffusion Process

### Forward Diffusion (Training)

```
Ground Truth Latent: z_gt [B,4,8,16,16]
                     â”‚
                     â–¼
        Sample timestep t ~ Uniform(0, 1000)
                     â”‚
                     â–¼
        Sample noise Îµ ~ N(0, I)
                     â”‚
                     â–¼
        z_noisy = âˆš(á¾±_t) Â· z_gt + âˆš(1-á¾±_t) Â· Îµ
                     â”‚
        [B,4,8,16,16]
```

**Noise Schedule**: Cosine schedule
- `t=0`: Clean latent (no noise)
- `t=1000`: Pure noise

### Reverse Diffusion (Inference)

```
Pure Noise: z_T ~ N(0, I) [B,4,8,16,16]
              â”‚
              â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  For t = T to 1: â”‚
   â”‚                  â”‚
   â”‚  1. Predict Îµ:   â”‚
   â”‚     Îµ = UNet(z_t, t, condition)
   â”‚                  â”‚
   â”‚  2. Denoise:     â”‚
   â”‚     z_{t-1} = (z_t - âˆš(1-á¾±_t)Â·Îµ) / âˆš(á¾±_t)
   â”‚                  â”‚
   â”‚  3. Add noise:   â”‚
   â”‚     z_{t-1} += Ïƒ_t Â· Îµ'  (if t > 1)
   â”‚                  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
    Clean Latent: z_0 [B,4,8,16,16]
              â”‚
              â–¼
        VAE Decoder
              â”‚
              â–¼
    Output Video: v_out [B,3,8,128,128]
```

**Sampling**: DDIM (50 steps for fast inference)

---

## Training Strategy

### Two-Phase Training

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Phase 1 (Epoch 0)                     â”‚
â”‚                                                          â”‚
â”‚  VAE: FROZEN â„ï¸  (requires_grad=False)                  â”‚
â”‚  U-Net: TRAINING ğŸ”¥ (requires_grad=True)                â”‚
â”‚                                                          â”‚
â”‚  Learning Rates:                                         â”‚
â”‚  â€¢ VAE Encoder: 0 (frozen)                              â”‚
â”‚  â€¢ VAE Decoder: 0 (frozen)                              â”‚
â”‚  â€¢ U-Net: 1e-4                                          â”‚
â”‚                                                          â”‚
â”‚  Goal: Learn denoising without changing VAE             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼  Automatic transition
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Phase 2 (Epoch 1+)                    â”‚
â”‚                                                          â”‚
â”‚  VAE: TRAINING ğŸ”¥ (requires_grad=True)                  â”‚
â”‚  U-Net: TRAINING ğŸ”¥ (requires_grad=True)                â”‚
â”‚                                                          â”‚
â”‚  Learning Rates:                                         â”‚
â”‚  â€¢ VAE Encoder: 1e-5 (10Ã— lower than U-Net)            â”‚
â”‚  â€¢ VAE Decoder: 1e-5 (10Ã— lower than U-Net)            â”‚
â”‚  â€¢ U-Net: 1e-4                                          â”‚
â”‚                                                          â”‚
â”‚  Goal: Fine-tune entire model end-to-end                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Benefits:**
1. Faster convergence (U-Net learns first)
2. Stable VAE features initially
3. Fine-tuning improves reconstruction quality
4. Better final performance

### Layer-Wise Learning Rates

| Component | Learning Rate | Multiplier | Parameters |
|-----------|--------------|------------|------------|
| U-Net (4-level) | 1e-4 | 1.0Ã— | 270M |
| VAE Encoder | 1e-5 | 0.1Ã— | 86M |
| VAE Decoder | 1e-5 | 0.1Ã— | 86M |

**Rationale**: VAE learns slower to preserve stable latent representations and maintain training stability.

---

## Layer Dimensions

### Complete Dimension Table

#### VAE Encoder Dimensions

| Layer | Input Shape | Output Shape | Channels | Spatial |
|-------|-------------|--------------|----------|---------|
| Input | - | (B,3,8,128,128) | 3 | 128Ã—128 |
| Conv_in | (B,3,8,128,128) | (B,128,8,128,128) | 128 | 128Ã—128 |
| Down1.ResBlock | (B,128,8,128,128) | (B,128,8,128,128) | 128 | 128Ã—128 |
| Down1.Downsample | (B,128,8,128,128) | (B,256,8,64,64) | 256 | 64Ã—64 |
| Down2.ResBlock | (B,256,8,64,64) | (B,256,8,64,64) | 256 | 64Ã—64 |
| Down2.Downsample | (B,256,8,64,64) | (B,512,8,32,32) | 512 | 32Ã—32 |
| Down3.ResBlock | (B,512,8,32,32) | (B,512,8,32,32) | 512 | 32Ã—32 |
| Down3.Downsample | (B,512,8,32,32) | (B,512,8,16,16) | 512 | 16Ã—16 |
| Mid.ResBlock | (B,512,8,16,16) | (B,512,8,16,16) | 512 | 16Ã—16 |
| Conv_out | (B,512,8,16,16) | (B,4,8,16,16) | 4 | 16Ã—16 |
| **Output** | - | **(B,4,8,16,16)** | **4** | **16Ã—16** |

**Compression**: 128Ã—128 â†’ 16Ã—16 = **8Ã— spatial reduction**

#### VAE Decoder Dimensions

| Layer | Input Shape | Output Shape | Channels | Spatial |
|-------|-------------|--------------|----------|---------|
| Input | - | (B,4,8,16,16) | 4 | 16Ã—16 |
| Conv_in | (B,4,8,16,16) | (B,512,8,16,16) | 512 | 16Ã—16 |
| Mid.ResBlock | (B,512,8,16,16) | (B,512,8,16,16) | 512 | 16Ã—16 |
| Up1.Upsample | (B,512,8,16,16) | (B,512,8,32,32) | 512 | 32Ã—32 |
| Up1.ResBlock | (B,512,8,32,32) | (B,512,8,32,32) | 512 | 32Ã—32 |
| Up2.Upsample | (B,512,8,32,32) | (B,256,8,64,64) | 256 | 64Ã—64 |
| Up2.ResBlock | (B,256,8,64,64) | (B,256,8,64,64) | 256 | 64Ã—64 |
| Up3.Upsample | (B,256,8,64,64) | (B,128,8,128,128) | 128 | 128Ã—128 |
| Up3.ResBlock | (B,128,8,128,128) | (B,128,8,128,128) | 128 | 128Ã—128 |
| Conv_out | (B,128,8,128,128) | (B,3,8,128,128) | 3 | 128Ã—128 |
| **Output** | - | **(B,3,8,128,128)** | **3** | **128Ã—128** |

**Expansion**: 16Ã—16 â†’ 128Ã—128 = **8Ã— spatial expansion**

#### U-Net Dimensions (4-Level Architecture)

| Level | Stage | Input Shape | Output Shape | Channels | Spatial |
|-------|-------|-------------|--------------|----------|---------|
| - | Input | - | (B,4,8,16,16) | 4 | 16Ã—16 |
| - | Conv_in | (B,4,8,16,16) | (B,128,8,16,16) | 128 | 16Ã—16 |
| 0 | Encoder | (B,128,8,16,16) | (B,128,8,16,16) | 128 | 16Ã—16 |
| 0 | Down | (B,128,8,16,16) | (B,256,8,8,8) | 256 | 8Ã—8 |
| 1 | Encoder | (B,256,8,8,8) | (B,256,8,8,8) | 256 | 8Ã—8 |
| 1 | Down | (B,256,8,8,8) | (B,512,8,4,4) | 512 | 4Ã—4 |
| 2 | Encoder | (B,512,8,4,4) | (B,512,8,4,4) | 512 | 4Ã—4 |
| 2 | Down | (B,512,8,4,4) | (B,512,8,2,2) | 512 | 2Ã—2 |
| 3 | Bottleneck | (B,512,8,2,2) | (B,512,8,2,2) | 512 | 2Ã—2 |
| 3 | Middle | (B,512,8,2,2) | (B,512,8,2,2) | 512 | 2Ã—2 |
| 2 | Decoder+Skip | (B,1024,8,2,2) | (B,512,8,2,2) | 512 | 2Ã—2 |
| 2 | Up | (B,512,8,2,2) | (B,512,8,4,4) | 512 | 4Ã—4 |
| 1 | Decoder+Skip | (B,1024,8,4,4) | (B,512,8,4,4) | 512 | 4Ã—4 |
| 1 | Up | (B,512,8,4,4) | (B,512,8,8,8) | 512 | 8Ã—8 |
| 0 | Decoder+Skip | (B,768,8,8,8) | (B,256,8,8,8) | 256 | 8Ã—8 |
| 0 | Up | (B,256,8,8,8) | (B,256,8,16,16) | 256 | 16Ã—16 |
| - | Final+Skip | (B,384,8,16,16) | (B,128,8,16,16) | 128 | 16Ã—16 |
| - | Conv_out | (B,128,8,16,16) | (B,4,8,16,16) | 4 | 16Ã—16 |
| - | **Output** | - | **(B,4,8,16,16)** | **4** | **16Ã—16** |

**Note**: Decoder channels increase due to skip connection concatenation. The 4th level doubles the model depth compared to 3-level architecture.

---

## Memory Requirements

### Training (Batch Size = 1, 128Ã—128, 8 frames)

| Component | Activation Memory | Weight Memory | Total |
|-----------|------------------|---------------|-------|
| VAE Encoder | ~500 MB | ~344 MB | ~844 MB |
| U-Net (4-level) | ~3.5 GB | ~1.08 GB | ~4.58 GB |
| VAE Decoder | ~500 MB | ~344 MB | ~844 MB |
| Optimizer States | - | ~3.5 GB | ~3.5 GB |
| **Total (Estimated)** | **~4.5 GB** | **~5.3 GB** | **~9.8 GB** |

**Recommended**: 16GB+ GPU for 128Ã—128 training

### Training (Batch Size = 1, 256Ã—256, 16 frames) - Production Config

| Component | Memory (without grad checkpoint) | Memory (with grad checkpoint) |
|-----------|----------------------------------|-------------------------------|
| Model Weights (FP16) | ~2 GB | ~2 GB |
| Activations | ~16 GB | ~8 GB |
| Gradients | ~2 GB | ~2 GB |
| Optimizer States | ~3.5 GB | ~3.5 GB |
| Overhead | ~1 GB | ~1 GB |
| **Total (Estimated)** | **~24.5 GB** | **~16.5 GB** |

**Critical**: Requires gradient checkpointing enabled for V100 32GB!

### Inference (Batch Size = 1)

| Component | Memory |
|-----------|--------|
| Model Weights | ~1.76 GB |
| Activations | ~1.5 GB |
| **Total (Estimated)** | **~3.3 GB** |

**Recommended**: 8GB+ GPU for inference

---

## Configuration Summary

### Current Training Config

```yaml
model:
  in_channels: 3
  latent_dim: 4
  vae_base_channels: 128        # Base channels = 128
  unet_model_channels: 128      # U-Net channels = 128
  unet_num_res_blocks: 2        # 2 ResBlocks per level
  unet_attention_levels: [1,2]  # Attention at levels 1 and 2
  unet_channel_mult: [1,2,4]    # Channel multipliers: 128,256,512

training:
  num_epochs: 2
  batch_size: 1
  learning_rate: 1e-4
  resolution: [128, 128]
  num_frames: 8

pretrained:
  two_phase_training: true
  phase1_epochs: 1
  layer_lr_multipliers:
    vae_encoder: 0.1
    vae_decoder: 0.1
    unet: 1.0
```

---

## Performance Characteristics

### Throughput Estimates

| Hardware | Batch Size | Samples/sec | Hours/Epoch (206 patients) |
|----------|-----------|-------------|---------------------------|
| Tesla V100 32GB | 1 | ~0.5 | ~2 hours |
| Tesla V100 32GB | 2 | ~0.8 | ~1.3 hours |
| A100 40GB | 2 | ~1.2 | ~0.9 hours |
| A100 40GB | 4 | ~2.0 | ~0.5 hours |

**Optimization Tips:**
- Enable mixed precision (`fp16`): 2Ã— speedup
- Gradient accumulation: Simulate larger batch sizes
- Reduce resolution for testing: 64Ã—64 â†’ 4Ã— faster

---

## Architecture Design Choices

### Why 3D Convolutions?

âœ… **Temporal coherence**: Maintains consistency across CT slices
âœ… **Efficiency**: Single model for all slices
âœ… **Context**: Each slice sees neighboring slices

vs 2D: Would process each slice independently

### Why Latent Diffusion?

âœ… **Efficiency**: 8Ã— compression â†’ 64Ã— fewer pixels to denoise
âœ… **Speed**: Faster training and inference
âœ… **Quality**: Focus computation on semantic features

vs Pixel Diffusion: Would denoise in full resolution (very slow)

### Why Two-Phase Training?

âœ… **Convergence**: U-Net learns quickly with fixed VAE
âœ… **Stability**: Prevents VAE collapse early in training
âœ… **Quality**: Fine-tuning adapts VAE to task

vs Joint Training: Can be unstable, slower convergence

---

## Summary

**Model**: Video-to-Video Latent Diffusion
**Parameters**: 335M total (172M VAE + 163M U-Net)
**Compression**: 8Ã— spatial (128â†’16)
**Strategy**: Two-phase training with layer-wise LR
**Memory**: ~7.5GB training, ~2.5GB inference
**Speed**: ~2 hours/epoch on V100

**Input**: Source CT video (8 slices, 128Ã—128, RGB)
**Output**: Enhanced CT video (8 slices, 128Ã—128, RGB)
**Latent**: Compressed representation (8 frames, 16Ã—16, 4 channels)

This architecture balances efficiency and quality for medical video-to-video translation tasks.
